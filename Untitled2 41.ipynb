{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # underlying library NLP tools\n",
    "from nltk.tokenize import word_tokenize # check nltk is downloaded\n",
    "import pandas as pd # for data hadnling\n",
    "import docx2txt # for pulling data from a word doc\n",
    "from textblob import TextBlob # for sentiment analysis\n",
    "import matplotlib.pyplot as plt # visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourfile=docx2txt.process(\"Horseracing.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(ourfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lower=[token.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/marcpuyoliniesta/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/js/3prtlh997knckqf8p2nq_dz80000gn/T/ipykernel_7955/3506944695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ClassMarc2/lib/python3.9/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ClassMarc2/lib/python3.9/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTKINTER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ClassMarc2/lib/python3.9/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m     \u001b[0;31m# /////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ClassMarc2/lib/python3.9/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thousands',\n",
       " 'of',\n",
       " 'racehorses',\n",
       " 'are',\n",
       " 'being',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'slaughterhouses',\n",
       " 'in',\n",
       " 'britain',\n",
       " 'and',\n",
       " 'ireland',\n",
       " ',',\n",
       " 'a',\n",
       " 'bbc',\n",
       " 'panorama',\n",
       " 'investigation',\n",
       " 'has',\n",
       " 'found',\n",
       " '.',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'slaughtered',\n",
       " 'animals',\n",
       " 'were',\n",
       " 'once',\n",
       " 'owned',\n",
       " 'and',\n",
       " 'trained',\n",
       " 'by',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'names',\n",
       " 'in',\n",
       " 'racing',\n",
       " '.',\n",
       " 'covert',\n",
       " 'recording',\n",
       " 'also',\n",
       " 'showed',\n",
       " 'how',\n",
       " 'rules',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'protect',\n",
       " 'horses',\n",
       " 'from',\n",
       " 'a',\n",
       " 'cruel',\n",
       " 'death',\n",
       " 'appear',\n",
       " 'to',\n",
       " 'be',\n",
       " 'regularly',\n",
       " 'ignored',\n",
       " 'at',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'uk',\n",
       " \"'s\",\n",
       " 'biggest',\n",
       " 'abattoirs',\n",
       " '.',\n",
       " 'the',\n",
       " 'abattoir',\n",
       " 'told',\n",
       " 'the',\n",
       " 'bbc',\n",
       " 'it',\n",
       " 'did',\n",
       " 'not',\n",
       " 'accept',\n",
       " 'any',\n",
       " 'form',\n",
       " 'of',\n",
       " 'animal',\n",
       " 'abuse',\n",
       " '.',\n",
       " 'one',\n",
       " 'expert',\n",
       " 'described',\n",
       " 'the',\n",
       " 'covert',\n",
       " 'footage',\n",
       " ',',\n",
       " 'from',\n",
       " 'cameras',\n",
       " 'installed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'campaign',\n",
       " 'group',\n",
       " 'animal',\n",
       " 'aid',\n",
       " ',',\n",
       " 'as',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'clear',\n",
       " 'breaches',\n",
       " 'of',\n",
       " 'the',\n",
       " 'regulations',\n",
       " '.',\n",
       " 'last',\n",
       " 'february',\n",
       " ',',\n",
       " 'a',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'top',\n",
       " 'trainer',\n",
       " 'gordon',\n",
       " 'elliott',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'a',\n",
       " 'dead',\n",
       " 'horse',\n",
       " 'sent',\n",
       " 'shockwaves',\n",
       " 'through',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'racing',\n",
       " 'and',\n",
       " 'beyond',\n",
       " '.',\n",
       " 'elliott',\n",
       " ',',\n",
       " 'who',\n",
       " 'has',\n",
       " 'trained',\n",
       " 'three',\n",
       " 'winners',\n",
       " 'of',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'national',\n",
       " ',',\n",
       " 'was',\n",
       " 'roundly',\n",
       " 'condemned',\n",
       " ',',\n",
       " 'and',\n",
       " 'suspended',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sport',\n",
       " 'until',\n",
       " '9',\n",
       " 'september',\n",
       " 'this',\n",
       " 'year',\n",
       " '.',\n",
       " 'the',\n",
       " 'incident',\n",
       " 'caused',\n",
       " 'uproar',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'also',\n",
       " 'highlighted',\n",
       " 'the',\n",
       " 'fate',\n",
       " 'of',\n",
       " 'many',\n",
       " 'horses',\n",
       " 'in',\n",
       " 'the',\n",
       " 'industry',\n",
       " 'who',\n",
       " 'die',\n",
       " 'while',\n",
       " 'racing',\n",
       " ',',\n",
       " 'in',\n",
       " 'training',\n",
       " 'or',\n",
       " 'in',\n",
       " 'abattoirs',\n",
       " '.',\n",
       " 'freedom',\n",
       " 'of',\n",
       " 'information',\n",
       " 'requests',\n",
       " 'revealed',\n",
       " 'that',\n",
       " '4,000',\n",
       " 'former',\n",
       " 'racehorses',\n",
       " 'were',\n",
       " 'slaughtered',\n",
       " 'in',\n",
       " 'britain',\n",
       " 'and',\n",
       " 'ireland',\n",
       " 'since',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " '2019',\n",
       " '.',\n",
       " 'most',\n",
       " ',',\n",
       " 'but',\n",
       " 'not',\n",
       " 'all',\n",
       " ',',\n",
       " 'were',\n",
       " 'trained',\n",
       " 'in',\n",
       " 'ireland',\n",
       " '.',\n",
       " 'animal',\n",
       " 'aid',\n",
       " ',',\n",
       " 'which',\n",
       " 'has',\n",
       " 'long',\n",
       " 'campaigned',\n",
       " 'for',\n",
       " 'an',\n",
       " 'end',\n",
       " 'to',\n",
       " 'horse',\n",
       " 'racing',\n",
       " ',',\n",
       " 'set',\n",
       " 'up',\n",
       " 'covert',\n",
       " 'cameras',\n",
       " 'at',\n",
       " 'drury',\n",
       " 'and',\n",
       " 'sons',\n",
       " ',',\n",
       " 'an',\n",
       " 'abattoir',\n",
       " 'in',\n",
       " 'england',\n",
       " 'which',\n",
       " 'has',\n",
       " 'a',\n",
       " 'licence',\n",
       " 'to',\n",
       " 'kill',\n",
       " 'horses',\n",
       " '.',\n",
       " '``',\n",
       " 'when',\n",
       " 'we',\n",
       " 'looked',\n",
       " 'at',\n",
       " 'the',\n",
       " 'footage',\n",
       " 'we',\n",
       " 'were',\n",
       " 'absolutely',\n",
       " 'astounded',\n",
       " 'at',\n",
       " 'the',\n",
       " 'sheer',\n",
       " 'volume',\n",
       " 'of',\n",
       " 'young',\n",
       " 'thoroughbreds',\n",
       " ',',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'animal',\n",
       " 'aid',\n",
       " 'spokesman',\n",
       " 'dene',\n",
       " 'stansall',\n",
       " '.',\n",
       " 'the',\n",
       " 'footage',\n",
       " 'was',\n",
       " 'recorded',\n",
       " 'over',\n",
       " 'four',\n",
       " 'days',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " '2019',\n",
       " 'and',\n",
       " 'the',\n",
       " 'start',\n",
       " 'of',\n",
       " '2020',\n",
       " '.',\n",
       " 'it',\n",
       " 'captured',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'former',\n",
       " 'racehorses',\n",
       " 'being',\n",
       " 'slaughtered',\n",
       " ',',\n",
       " 'the',\n",
       " 'majority',\n",
       " 'of',\n",
       " 'them',\n",
       " 'from',\n",
       " 'ireland',\n",
       " 'and',\n",
       " 'the',\n",
       " 'majority',\n",
       " 'young',\n",
       " '.',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'horses',\n",
       " 'shot',\n",
       " 'in',\n",
       " 'the',\n",
       " 'abattoir',\n",
       " 'had',\n",
       " 'previous',\n",
       " 'illustrious',\n",
       " 'racing',\n",
       " 'careers',\n",
       " ',',\n",
       " 'winning',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'pounds',\n",
       " '.',\n",
       " 'three',\n",
       " 'of',\n",
       " 'them',\n",
       " 'had',\n",
       " 'been',\n",
       " 'trained',\n",
       " 'by',\n",
       " 'gordon',\n",
       " 'elliott',\n",
       " 'at',\n",
       " 'his',\n",
       " 'state-of-the-art',\n",
       " 'stables',\n",
       " 'in',\n",
       " 'county',\n",
       " 'meath',\n",
       " ',',\n",
       " 'ireland',\n",
       " '.',\n",
       " 'he',\n",
       " 'told',\n",
       " 'panorama',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'three',\n",
       " 'animals',\n",
       " 'were',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'the',\n",
       " 'abattoir',\n",
       " 'by',\n",
       " 'him',\n",
       " '.',\n",
       " 'the',\n",
       " 'horses',\n",
       " 'had',\n",
       " 'retired',\n",
       " 'from',\n",
       " 'racing',\n",
       " 'due',\n",
       " 'to',\n",
       " 'injury',\n",
       " ',',\n",
       " 'he',\n",
       " 'said',\n",
       " ',',\n",
       " 'and',\n",
       " 'were',\n",
       " 'not',\n",
       " 'under',\n",
       " 'his',\n",
       " 'care',\n",
       " 'when',\n",
       " 'they',\n",
       " 'were',\n",
       " 'killed',\n",
       " '.',\n",
       " 'elliott',\n",
       " 'said',\n",
       " 'two',\n",
       " 'of',\n",
       " 'the',\n",
       " 'horses',\n",
       " 'were',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'a',\n",
       " 'horse',\n",
       " 'dealer',\n",
       " '``',\n",
       " 'to',\n",
       " 'be',\n",
       " 'rehomed',\n",
       " 'if',\n",
       " 'possible',\n",
       " ',',\n",
       " 'and',\n",
       " 'if',\n",
       " 'not',\n",
       " ',',\n",
       " 'to',\n",
       " 'be',\n",
       " 'humanely',\n",
       " 'euthanised',\n",
       " \"''\",\n",
       " 'in',\n",
       " 'line',\n",
       " 'with',\n",
       " 'the',\n",
       " 'regulations',\n",
       " '.',\n",
       " 'he',\n",
       " 'said',\n",
       " 'he',\n",
       " 'gave',\n",
       " 'the',\n",
       " 'third',\n",
       " 'horse',\n",
       " 'to',\n",
       " 'another',\n",
       " 'rider',\n",
       " 'as',\n",
       " 'requested',\n",
       " 'by',\n",
       " 'its',\n",
       " 'owner',\n",
       " '.',\n",
       " 'and',\n",
       " 'he',\n",
       " 'said',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'he',\n",
       " 'learned',\n",
       " 'of',\n",
       " 'their',\n",
       " 'fate',\n",
       " 'was',\n",
       " 'when',\n",
       " 'panorama',\n",
       " 'contacted',\n",
       " 'him',\n",
       " '.',\n",
       " 'elliott',\n",
       " 'said',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ensured',\n",
       " 'the',\n",
       " 'appropriate',\n",
       " 'and',\n",
       " 'proper',\n",
       " 'treatment',\n",
       " 'and',\n",
       " 'welfare',\n",
       " 'of',\n",
       " 'animals',\n",
       " 'that',\n",
       " 'have',\n",
       " 'been',\n",
       " 'in',\n",
       " 'his',\n",
       " 'possession',\n",
       " 'and',\n",
       " 'has',\n",
       " 'rehomed',\n",
       " 'a',\n",
       " 'substantial',\n",
       " 'number',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'animal',\n",
       " 'aid',\n",
       " \"'s\",\n",
       " 'cameras',\n",
       " 'also',\n",
       " 'captured',\n",
       " 'what',\n",
       " 'appear',\n",
       " 'to',\n",
       " 'be',\n",
       " 'breaches',\n",
       " 'of',\n",
       " 'rules',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'protect',\n",
       " 'animals',\n",
       " 'from',\n",
       " 'unnecessary',\n",
       " 'cruelty',\n",
       " '.',\n",
       " 'the',\n",
       " 'regulations',\n",
       " 'say',\n",
       " 'horses',\n",
       " 'should',\n",
       " 'not',\n",
       " 'be',\n",
       " 'killed',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'the',\n",
       " 'footage',\n",
       " 'recorded',\n",
       " 'horses',\n",
       " 'being',\n",
       " 'shot',\n",
       " 'together',\n",
       " '26',\n",
       " 'times',\n",
       " 'over',\n",
       " 'the',\n",
       " 'four',\n",
       " 'days',\n",
       " 'of',\n",
       " 'filming',\n",
       " '.',\n",
       " 'prof',\n",
       " 'daniel',\n",
       " 'mills',\n",
       " ',',\n",
       " 'a',\n",
       " 'veterinary',\n",
       " 'behavioural',\n",
       " 'specialist',\n",
       " 'from',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'lincoln',\n",
       " ',',\n",
       " 'who',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'the',\n",
       " 'footage',\n",
       " ',',\n",
       " 'said',\n",
       " ':',\n",
       " '``',\n",
       " 'a',\n",
       " 'gunshot',\n",
       " 'going',\n",
       " 'off',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'startling',\n",
       " ',',\n",
       " 'seeing',\n",
       " 'another',\n",
       " 'horse',\n",
       " 'suddenly',\n",
       " 'drop',\n",
       " ',',\n",
       " 'these',\n",
       " 'are',\n",
       " 'all',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'very',\n",
       " 'distressing',\n",
       " 'for',\n",
       " 'a',\n",
       " 'horse',\n",
       " 'in',\n",
       " 'this',\n",
       " 'situation',\n",
       " '.',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'is',\n",
       " 'not',\n",
       " 'the',\n",
       " 'only',\n",
       " 'breach',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rules',\n",
       " '.',\n",
       " 'the',\n",
       " 'regulations',\n",
       " 'also',\n",
       " 'say',\n",
       " 'every',\n",
       " 'effort',\n",
       " 'should',\n",
       " 'be',\n",
       " 'made',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'a',\n",
       " 'rapid',\n",
       " 'death',\n",
       " '.',\n",
       " 'but',\n",
       " 'the',\n",
       " 'footage',\n",
       " 'showed',\n",
       " 'that',\n",
       " 'sometimes',\n",
       " 'the',\n",
       " 'death',\n",
       " 'was',\n",
       " 'far',\n",
       " 'from',\n",
       " 'instant',\n",
       " '.',\n",
       " 'on',\n",
       " '91',\n",
       " 'occasions',\n",
       " 'the',\n",
       " 'cameras',\n",
       " 'recorded',\n",
       " 'a',\n",
       " 'slaughterman',\n",
       " 'shooting',\n",
       " 'horses',\n",
       " ',',\n",
       " 'not',\n",
       " 'close',\n",
       " 'up',\n",
       " ',',\n",
       " 'but',\n",
       " 'from',\n",
       " 'a',\n",
       " 'distance',\n",
       " '.',\n",
       " 'reviewing',\n",
       " 'the',\n",
       " 'footage',\n",
       " 'of',\n",
       " 'one',\n",
       " 'such',\n",
       " 'killing',\n",
       " ',',\n",
       " 'prof',\n",
       " 'mills',\n",
       " 'said',\n",
       " ':',\n",
       " '``',\n",
       " 'it',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'look',\n",
       " 'like',\n",
       " 'the',\n",
       " 'horse',\n",
       " 'is',\n",
       " 'even',\n",
       " 'stunned',\n",
       " '.',\n",
       " 'you',\n",
       " 'can',\n",
       " 'see',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'turning',\n",
       " 'its',\n",
       " 'head',\n",
       " '.',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'have',\n",
       " 'got',\n",
       " 'some',\n",
       " 'control',\n",
       " 'actually',\n",
       " 'over',\n",
       " 'its',\n",
       " 'head',\n",
       " 'and',\n",
       " 'neck',\n",
       " '.',\n",
       " '``',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'shot',\n",
       " 'from',\n",
       " 'a',\n",
       " 'distance',\n",
       " 'at',\n",
       " 'a',\n",
       " 'horse',\n",
       " ',',\n",
       " 'to',\n",
       " 'me',\n",
       " ',',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'completely',\n",
       " 'out',\n",
       " 'of',\n",
       " 'order',\n",
       " '.',\n",
       " 'if',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'euthanise',\n",
       " 'a',\n",
       " 'horse',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ve\",\n",
       " 'got',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'bullet',\n",
       " 'in',\n",
       " 'the',\n",
       " 'right',\n",
       " 'place',\n",
       " '.',\n",
       " '``',\n",
       " 'if',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'representative',\n",
       " 'of',\n",
       " 'how',\n",
       " 'they',\n",
       " \"'re\",\n",
       " 'being',\n",
       " 'killed',\n",
       " ',',\n",
       " 'then',\n",
       " 'we',\n",
       " \"'ve\",\n",
       " 'got',\n",
       " 'a',\n",
       " 'really',\n",
       " 'serious',\n",
       " 'problem',\n",
       " '.',\n",
       " \"''\",\n",
       " 'the',\n",
       " 'abattoir',\n",
       " ',',\n",
       " 'drury',\n",
       " 'and',\n",
       " 'sons',\n",
       " ',',\n",
       " 'told',\n",
       " 'panorama',\n",
       " 'that',\n",
       " 'they',\n",
       " '``',\n",
       " 'take',\n",
       " 'great',\n",
       " 'care',\n",
       " 'to',\n",
       " 'maintain',\n",
       " 'high',\n",
       " 'welfare',\n",
       " 'conditions',\n",
       " 'and',\n",
       " 'do',\n",
       " 'not',\n",
       " 'accept',\n",
       " 'any',\n",
       " 'form',\n",
       " 'of',\n",
       " 'animal',\n",
       " 'abuse',\n",
       " \"''\",\n",
       " '.',\n",
       " 'they',\n",
       " 'said',\n",
       " 'all',\n",
       " 'horses',\n",
       " 'are',\n",
       " '``',\n",
       " 'humanely',\n",
       " 'destroyed',\n",
       " \"''\",\n",
       " 'and',\n",
       " 'that',\n",
       " 'on',\n",
       " 'occasions',\n",
       " 'where',\n",
       " 'issues',\n",
       " 'do',\n",
       " 'occur',\n",
       " ',',\n",
       " 'they',\n",
       " 'take',\n",
       " '``',\n",
       " 'swift',\n",
       " 'action',\n",
       " 'to',\n",
       " 'review',\n",
       " 'and',\n",
       " 'rectify',\n",
       " \"''\",\n",
       " 'them',\n",
       " '.',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'racehorses',\n",
       " 'killed',\n",
       " 'while',\n",
       " 'animal',\n",
       " 'aid',\n",
       " 'cameras',\n",
       " 'were',\n",
       " 'filming',\n",
       " 'had',\n",
       " 'been',\n",
       " 'transported',\n",
       " 'from',\n",
       " 'ireland',\n",
       " ',',\n",
       " 'travelling',\n",
       " 'more',\n",
       " 'than',\n",
       " '350',\n",
       " 'miles',\n",
       " '(',\n",
       " '560km',\n",
       " ')',\n",
       " 'by',\n",
       " 'road',\n",
       " 'and',\n",
       " 'sea',\n",
       " '.',\n",
       " 'some',\n",
       " 'animals',\n",
       " 'were',\n",
       " 'said',\n",
       " 'to',\n",
       " 'be',\n",
       " 'carrying',\n",
       " 'career-ending',\n",
       " 'injuries',\n",
       " '.',\n",
       " 'veterinary',\n",
       " 'expert',\n",
       " 'dr',\n",
       " 'hannah',\n",
       " 'donovan',\n",
       " ',',\n",
       " 'who',\n",
       " 'reviewed',\n",
       " 'the',\n",
       " 'footage',\n",
       " ',',\n",
       " 'said',\n",
       " ':',\n",
       " '``',\n",
       " '[',\n",
       " 'travelling',\n",
       " ']',\n",
       " '350',\n",
       " 'miles',\n",
       " 'potentially',\n",
       " 'carrying',\n",
       " 'an',\n",
       " 'injury',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'humane',\n",
       " 'process',\n",
       " '.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'unnecessary',\n",
       " 'suffering',\n",
       " '.',\n",
       " \"''\",\n",
       " 'dr',\n",
       " 'donovan',\n",
       " 'said',\n",
       " ':',\n",
       " '``',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'is',\n",
       " 'horses',\n",
       " ',',\n",
       " 'if',\n",
       " 'they',\n",
       " 'are',\n",
       " 'to',\n",
       " 'be',\n",
       " 'euthanised',\n",
       " ',',\n",
       " 'could',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'euthanised',\n",
       " 'at',\n",
       " 'home',\n",
       " '.',\n",
       " 'simple',\n",
       " 'as',\n",
       " 'that',\n",
       " '.',\n",
       " \"''\",\n",
       " 'prof',\n",
       " 'mills',\n",
       " 'said',\n",
       " 'the',\n",
       " 'racing',\n",
       " 'authorities',\n",
       " \"'\",\n",
       " 'own',\n",
       " 'guidelines',\n",
       " 'clearly',\n",
       " 'set',\n",
       " 'out',\n",
       " 'what',\n",
       " 'should',\n",
       " 'happen',\n",
       " 'to',\n",
       " 'horses',\n",
       " 'when',\n",
       " 'their',\n",
       " 'racing',\n",
       " 'career',\n",
       " 'ends',\n",
       " '.',\n",
       " '``',\n",
       " 'the',\n",
       " 'industry',\n",
       " \"'s\",\n",
       " 'own',\n",
       " 'regulations',\n",
       " 'recommend',\n",
       " 'that',\n",
       " 'you',\n",
       " 'should',\n",
       " 'make',\n",
       " 'provision',\n",
       " 'for',\n",
       " 'all',\n",
       " 'the',\n",
       " 'animals',\n",
       " 'that',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'responsible',\n",
       " 'for',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'said',\n",
       " '.',\n",
       " 'horse',\n",
       " 'racing',\n",
       " 'ireland',\n",
       " ',',\n",
       " 'the',\n",
       " 'governing',\n",
       " 'body',\n",
       " 'for',\n",
       " 'racing',\n",
       " 'in',\n",
       " 'ireland',\n",
       " ',',\n",
       " 'said',\n",
       " 'it',\n",
       " 'placed',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqdist1=nltk.FreqDist(tokens_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq1=dict((word, freq) for word,freq in freqdist1.items() if not word.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_freq1=sorted(word_freq1.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 64),\n",
       " ('.', 52),\n",
       " (',', 51),\n",
       " ('of', 43),\n",
       " ('to', 28),\n",
       " ('and', 25),\n",
       " ('a', 22),\n",
       " ('in', 18),\n",
       " ('said', 18),\n",
       " ('``', 16),\n",
       " ('horses', 14),\n",
       " ('racing', 13),\n",
       " (\"''\", 13),\n",
       " ('that', 12),\n",
       " ('from', 11),\n",
       " ('be', 11),\n",
       " ('it', 11),\n",
       " ('horse', 11),\n",
       " ('were', 10),\n",
       " ('at', 9),\n",
       " ('not', 9),\n",
       " ('ireland', 8),\n",
       " ('has', 8),\n",
       " ('animal', 8),\n",
       " ('footage', 8),\n",
       " ('he', 8),\n",
       " ('by', 7),\n",
       " ('on', 7),\n",
       " ('is', 7),\n",
       " ('panorama', 6),\n",
       " ('some', 6),\n",
       " ('animals', 6),\n",
       " (\"'s\", 6),\n",
       " ('aid', 6),\n",
       " ('for', 6),\n",
       " ('they', 6),\n",
       " (':', 6),\n",
       " ('are', 5),\n",
       " ('being', 5),\n",
       " ('abattoir', 5),\n",
       " ('cameras', 5),\n",
       " ('regulations', 5),\n",
       " ('elliott', 5),\n",
       " ('was', 5),\n",
       " ('but', 5),\n",
       " ('killed', 5),\n",
       " ('if', 5),\n",
       " ('should', 5),\n",
       " ('you', 5),\n",
       " ('racehorses', 4),\n",
       " ('sent', 4),\n",
       " ('bbc', 4),\n",
       " ('trained', 4),\n",
       " ('also', 4),\n",
       " ('one', 4),\n",
       " ('who', 4),\n",
       " ('all', 4),\n",
       " ('when', 4),\n",
       " ('them', 4),\n",
       " ('had', 4),\n",
       " ('welfare', 4),\n",
       " ('going', 4),\n",
       " ('i', 4),\n",
       " ('slaughtered', 3),\n",
       " ('covert', 3),\n",
       " ('rules', 3),\n",
       " ('death', 3),\n",
       " ('told', 3),\n",
       " ('any', 3),\n",
       " ('as', 3),\n",
       " ('three', 3),\n",
       " ('this', 3),\n",
       " ('industry', 3),\n",
       " ('an', 3),\n",
       " ('we', 3),\n",
       " ('recorded', 3),\n",
       " ('over', 3),\n",
       " ('shot', 3),\n",
       " ('been', 3),\n",
       " ('his', 3),\n",
       " ('care', 3),\n",
       " ('euthanised', 3),\n",
       " ('its', 3),\n",
       " ('prof', 3),\n",
       " ('mills', 3),\n",
       " ('can', 3),\n",
       " ('got', 3),\n",
       " (\"'re\", 3),\n",
       " ('thousands', 2),\n",
       " ('slaughterhouses', 2),\n",
       " ('britain', 2),\n",
       " ('biggest', 2),\n",
       " ('showed', 2),\n",
       " ('how', 2),\n",
       " ('designed', 2),\n",
       " ('protect', 2),\n",
       " ('appear', 2),\n",
       " ('abattoirs', 2),\n",
       " ('accept', 2),\n",
       " ('form', 2),\n",
       " ('abuse', 2),\n",
       " ('expert', 2),\n",
       " ('clear', 2),\n",
       " ('breaches', 2),\n",
       " ('gordon', 2),\n",
       " ('fate', 2),\n",
       " ('while', 2),\n",
       " ('or', 2),\n",
       " ('former', 2),\n",
       " ('which', 2),\n",
       " ('end', 2),\n",
       " ('set', 2),\n",
       " ('up', 2),\n",
       " ('drury', 2),\n",
       " ('sons', 2),\n",
       " ('young', 2),\n",
       " ('dene', 2),\n",
       " ('stansall', 2),\n",
       " ('four', 2),\n",
       " ('days', 2),\n",
       " ('captured', 2),\n",
       " ('majority', 2),\n",
       " ('him', 2),\n",
       " ('injury', 2),\n",
       " ('rehomed', 2),\n",
       " ('humanely', 2),\n",
       " ('line', 2),\n",
       " ('another', 2),\n",
       " ('their', 2),\n",
       " ('have', 2),\n",
       " ('number', 2),\n",
       " ('what', 2),\n",
       " ('unnecessary', 2),\n",
       " ('say', 2),\n",
       " ('filming', 2),\n",
       " ('veterinary', 2),\n",
       " ('occasions', 2),\n",
       " ('distance', 2),\n",
       " ('head', 2),\n",
       " ('out', 2),\n",
       " (\"'ve\", 2),\n",
       " ('take', 2),\n",
       " ('great', 2),\n",
       " ('high', 2),\n",
       " ('do', 2),\n",
       " ('issues', 2),\n",
       " ('travelling', 2),\n",
       " ('miles', 2),\n",
       " ('carrying', 2),\n",
       " ('dr', 2),\n",
       " ('donovan', 2),\n",
       " ('[', 2),\n",
       " (']', 2),\n",
       " ('own', 2),\n",
       " ('people', 2),\n",
       " ('would', 2),\n",
       " ('attracted', 2),\n",
       " ('because', 2),\n",
       " ('investigation', 1),\n",
       " ('found', 1),\n",
       " ('once', 1),\n",
       " ('owned', 1),\n",
       " ('names', 1),\n",
       " ('recording', 1),\n",
       " ('cruel', 1),\n",
       " ('regularly', 1),\n",
       " ('ignored', 1),\n",
       " ('uk', 1),\n",
       " ('did', 1),\n",
       " ('described', 1),\n",
       " ('installed', 1),\n",
       " ('campaign', 1),\n",
       " ('group', 1),\n",
       " ('evidence', 1),\n",
       " ('last', 1),\n",
       " ('february', 1),\n",
       " ('picture', 1),\n",
       " ('top', 1),\n",
       " ('trainer', 1),\n",
       " ('sitting', 1),\n",
       " ('dead', 1),\n",
       " ('shockwaves', 1),\n",
       " ('through', 1),\n",
       " ('world', 1),\n",
       " ('beyond', 1),\n",
       " ('winners', 1),\n",
       " ('grand', 1),\n",
       " ('national', 1),\n",
       " ('roundly', 1),\n",
       " ('condemned', 1),\n",
       " ('suspended', 1),\n",
       " ('sport', 1),\n",
       " ('until', 1),\n",
       " ('september', 1),\n",
       " ('year', 1),\n",
       " ('incident', 1),\n",
       " ('caused', 1),\n",
       " ('uproar', 1),\n",
       " ('highlighted', 1),\n",
       " ('many', 1),\n",
       " ('die', 1),\n",
       " ('training', 1),\n",
       " ('freedom', 1),\n",
       " ('information', 1),\n",
       " ('requests', 1),\n",
       " ('revealed', 1),\n",
       " ('4,000', 1),\n",
       " ('since', 1),\n",
       " ('beginning', 1),\n",
       " ('most', 1),\n",
       " ('long', 1),\n",
       " ('campaigned', 1),\n",
       " ('england', 1),\n",
       " ('licence', 1),\n",
       " ('kill', 1),\n",
       " ('looked', 1),\n",
       " ('absolutely', 1),\n",
       " ('astounded', 1),\n",
       " ('sheer', 1),\n",
       " ('volume', 1),\n",
       " ('thoroughbreds', 1),\n",
       " ('spokesman', 1),\n",
       " ('start', 1),\n",
       " ('dozens', 1),\n",
       " ('previous', 1),\n",
       " ('illustrious', 1),\n",
       " ('careers', 1),\n",
       " ('winning', 1),\n",
       " ('pounds', 1),\n",
       " ('state-of-the-art', 1),\n",
       " ('stables', 1),\n",
       " ('county', 1),\n",
       " ('meath', 1),\n",
       " ('none', 1),\n",
       " ('retired', 1),\n",
       " ('due', 1),\n",
       " ('under', 1),\n",
       " ('two', 1),\n",
       " ('dealer', 1),\n",
       " ('possible', 1),\n",
       " ('with', 1),\n",
       " ('gave', 1),\n",
       " ('third', 1),\n",
       " ('rider', 1),\n",
       " ('requested', 1),\n",
       " ('owner', 1),\n",
       " ('first', 1),\n",
       " ('time', 1),\n",
       " ('learned', 1),\n",
       " ('contacted', 1),\n",
       " ('ensured', 1),\n",
       " ('appropriate', 1),\n",
       " ('proper', 1),\n",
       " ('treatment', 1),\n",
       " ('possession', 1),\n",
       " ('substantial', 1),\n",
       " ('cruelty', 1),\n",
       " ('sight', 1),\n",
       " ('each', 1),\n",
       " ('other', 1),\n",
       " ('together', 1),\n",
       " ('times', 1),\n",
       " ('daniel', 1),\n",
       " ('behavioural', 1),\n",
       " ('specialist', 1),\n",
       " ('university', 1),\n",
       " ('lincoln', 1),\n",
       " ('seen', 1),\n",
       " ('gunshot', 1),\n",
       " ('off', 1),\n",
       " ('startling', 1),\n",
       " ('seeing', 1),\n",
       " ('suddenly', 1),\n",
       " ('drop', 1),\n",
       " ('these', 1),\n",
       " ('very', 1),\n",
       " ('distressing', 1),\n",
       " ('situation', 1),\n",
       " ('only', 1),\n",
       " ('breach', 1),\n",
       " ('every', 1),\n",
       " ('effort', 1),\n",
       " ('made', 1),\n",
       " ('ensure', 1),\n",
       " ('rapid', 1),\n",
       " ('sometimes', 1),\n",
       " ('far', 1),\n",
       " ('instant', 1),\n",
       " ('slaughterman', 1),\n",
       " ('shooting', 1),\n",
       " ('close', 1),\n",
       " ('reviewing', 1),\n",
       " ('such', 1),\n",
       " ('killing', 1),\n",
       " ('does', 1),\n",
       " (\"n't\", 1),\n",
       " ('look', 1),\n",
       " ('like', 1),\n",
       " ('even', 1),\n",
       " ('stunned', 1),\n",
       " ('see', 1),\n",
       " ('turning', 1),\n",
       " ('seems', 1),\n",
       " ('control', 1),\n",
       " ('actually', 1),\n",
       " ('neck', 1),\n",
       " ('taking', 1),\n",
       " ('me', 1),\n",
       " ('completely', 1),\n",
       " ('order', 1),\n",
       " ('euthanise', 1),\n",
       " ('get', 1),\n",
       " ('bullet', 1),\n",
       " ('right', 1),\n",
       " ('place', 1),\n",
       " ('representative', 1),\n",
       " ('then', 1),\n",
       " ('really', 1),\n",
       " ('serious', 1),\n",
       " ('problem', 1),\n",
       " ('maintain', 1),\n",
       " ('conditions', 1),\n",
       " ('destroyed', 1),\n",
       " ('where', 1),\n",
       " ('occur', 1),\n",
       " ('swift', 1),\n",
       " ('action', 1),\n",
       " ('review', 1),\n",
       " ('rectify', 1),\n",
       " ('transported', 1),\n",
       " ('more', 1),\n",
       " ('than', 1),\n",
       " ('(', 1),\n",
       " ('560km', 1),\n",
       " (')', 1),\n",
       " ('road', 1),\n",
       " ('sea', 1),\n",
       " ('career-ending', 1),\n",
       " ('injuries', 1),\n",
       " ('hannah', 1),\n",
       " ('reviewed', 1),\n",
       " ('potentially', 1),\n",
       " ('humane', 1),\n",
       " ('process', 1),\n",
       " ('suffering', 1),\n",
       " ('bottom', 1),\n",
       " ('could', 1),\n",
       " ('home', 1),\n",
       " ('simple', 1),\n",
       " ('authorities', 1),\n",
       " (\"'\", 1),\n",
       " ('guidelines', 1),\n",
       " ('clearly', 1),\n",
       " ('happen', 1),\n",
       " ('career', 1),\n",
       " ('ends', 1),\n",
       " ('recommend', 1),\n",
       " ('make', 1),\n",
       " ('provision', 1),\n",
       " ('responsible', 1),\n",
       " ('governing', 1),\n",
       " ('body', 1),\n",
       " ('placed', 1),\n",
       " ('importance', 1),\n",
       " ('british', 1),\n",
       " ('horseracing', 1),\n",
       " ('authority', 1),\n",
       " ('demonstrated', 1),\n",
       " ('commitment', 1),\n",
       " ('improving', 1),\n",
       " ('already', 1),\n",
       " ('standards', 1),\n",
       " ('racehorses…', 1),\n",
       " ('before', 1),\n",
       " ('during', 1),\n",
       " ('after', 1),\n",
       " ('consider', 1),\n",
       " ('carefully', 1),\n",
       " ('raised', 1),\n",
       " ('programme', 1),\n",
       " ('understand', 1),\n",
       " ('why', 1),\n",
       " ('myself', 1),\n",
       " ('poor', 1),\n",
       " ('record', 1),\n",
       " ('dying', 1),\n",
       " ('no', 1),\n",
       " ('longer', 1),\n",
       " ('support', 1),\n",
       " ('-', 1),\n",
       " ('think', 1),\n",
       " ('lot', 1),\n",
       " ('public', 1),\n",
       " ('feel', 1),\n",
       " ('same', 1),\n",
       " ('way', 1),\n",
       " ('dark', 1),\n",
       " ('side', 1),\n",
       " ('monday', 1),\n",
       " ('20:30', 1),\n",
       " ('bst', 1),\n",
       " ('watch', 1),\n",
       " ('later', 1),\n",
       " ('iplayer', 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens_lower=[word for word in tokens_lower if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens_lower_without_stop=[word for word in clean_tokens_lower if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqdist2=nltk.FreqDist(clean_tokens_lower_without_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq2=dict((word, freq) for word,freq in freqdist2.items() if not word.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_freq2=sorted(word_freq2.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 18),\n",
       " ('horses', 14),\n",
       " ('racing', 13),\n",
       " ('horse', 11),\n",
       " ('ireland', 8),\n",
       " ('animal', 8),\n",
       " ('footage', 8),\n",
       " ('panorama', 6),\n",
       " ('animals', 6),\n",
       " ('aid', 6),\n",
       " ('abattoir', 5),\n",
       " ('cameras', 5),\n",
       " ('regulations', 5),\n",
       " ('elliott', 5),\n",
       " ('killed', 5),\n",
       " ('racehorses', 4),\n",
       " ('sent', 4),\n",
       " ('bbc', 4),\n",
       " ('trained', 4),\n",
       " ('also', 4),\n",
       " ('one', 4),\n",
       " ('welfare', 4),\n",
       " ('going', 4),\n",
       " ('slaughtered', 3),\n",
       " ('covert', 3),\n",
       " ('rules', 3),\n",
       " ('death', 3),\n",
       " ('told', 3),\n",
       " ('three', 3),\n",
       " ('industry', 3),\n",
       " ('recorded', 3),\n",
       " ('shot', 3),\n",
       " ('care', 3),\n",
       " ('euthanised', 3),\n",
       " ('prof', 3),\n",
       " ('mills', 3),\n",
       " ('got', 3),\n",
       " ('thousands', 2),\n",
       " ('slaughterhouses', 2),\n",
       " ('britain', 2),\n",
       " ('biggest', 2),\n",
       " ('showed', 2),\n",
       " ('designed', 2),\n",
       " ('protect', 2),\n",
       " ('appear', 2),\n",
       " ('abattoirs', 2),\n",
       " ('accept', 2),\n",
       " ('form', 2),\n",
       " ('abuse', 2),\n",
       " ('expert', 2),\n",
       " ('clear', 2),\n",
       " ('breaches', 2),\n",
       " ('gordon', 2),\n",
       " ('fate', 2),\n",
       " ('former', 2),\n",
       " ('end', 2),\n",
       " ('set', 2),\n",
       " ('drury', 2),\n",
       " ('sons', 2),\n",
       " ('young', 2),\n",
       " ('dene', 2),\n",
       " ('stansall', 2),\n",
       " ('four', 2),\n",
       " ('days', 2),\n",
       " ('captured', 2),\n",
       " ('majority', 2),\n",
       " ('injury', 2),\n",
       " ('rehomed', 2),\n",
       " ('humanely', 2),\n",
       " ('line', 2),\n",
       " ('another', 2),\n",
       " ('number', 2),\n",
       " ('unnecessary', 2),\n",
       " ('say', 2),\n",
       " ('filming', 2),\n",
       " ('veterinary', 2),\n",
       " ('occasions', 2),\n",
       " ('distance', 2),\n",
       " ('head', 2),\n",
       " ('take', 2),\n",
       " ('great', 2),\n",
       " ('high', 2),\n",
       " ('issues', 2),\n",
       " ('travelling', 2),\n",
       " ('miles', 2),\n",
       " ('carrying', 2),\n",
       " ('dr', 2),\n",
       " ('donovan', 2),\n",
       " ('people', 2),\n",
       " ('would', 2),\n",
       " ('attracted', 2),\n",
       " ('investigation', 1),\n",
       " ('found', 1),\n",
       " ('owned', 1),\n",
       " ('names', 1),\n",
       " ('recording', 1),\n",
       " ('cruel', 1),\n",
       " ('regularly', 1),\n",
       " ('ignored', 1),\n",
       " ('uk', 1),\n",
       " ('described', 1),\n",
       " ('installed', 1),\n",
       " ('campaign', 1),\n",
       " ('group', 1),\n",
       " ('evidence', 1),\n",
       " ('last', 1),\n",
       " ('february', 1),\n",
       " ('picture', 1),\n",
       " ('top', 1),\n",
       " ('trainer', 1),\n",
       " ('sitting', 1),\n",
       " ('dead', 1),\n",
       " ('shockwaves', 1),\n",
       " ('world', 1),\n",
       " ('beyond', 1),\n",
       " ('winners', 1),\n",
       " ('grand', 1),\n",
       " ('national', 1),\n",
       " ('roundly', 1),\n",
       " ('condemned', 1),\n",
       " ('suspended', 1),\n",
       " ('sport', 1),\n",
       " ('september', 1),\n",
       " ('year', 1),\n",
       " ('incident', 1),\n",
       " ('caused', 1),\n",
       " ('uproar', 1),\n",
       " ('highlighted', 1),\n",
       " ('many', 1),\n",
       " ('die', 1),\n",
       " ('training', 1),\n",
       " ('freedom', 1),\n",
       " ('information', 1),\n",
       " ('requests', 1),\n",
       " ('revealed', 1),\n",
       " ('since', 1),\n",
       " ('beginning', 1),\n",
       " ('long', 1),\n",
       " ('campaigned', 1),\n",
       " ('england', 1),\n",
       " ('licence', 1),\n",
       " ('kill', 1),\n",
       " ('looked', 1),\n",
       " ('absolutely', 1),\n",
       " ('astounded', 1),\n",
       " ('sheer', 1),\n",
       " ('volume', 1),\n",
       " ('thoroughbreds', 1),\n",
       " ('spokesman', 1),\n",
       " ('start', 1),\n",
       " ('dozens', 1),\n",
       " ('previous', 1),\n",
       " ('illustrious', 1),\n",
       " ('careers', 1),\n",
       " ('winning', 1),\n",
       " ('pounds', 1),\n",
       " ('stables', 1),\n",
       " ('county', 1),\n",
       " ('meath', 1),\n",
       " ('none', 1),\n",
       " ('retired', 1),\n",
       " ('due', 1),\n",
       " ('two', 1),\n",
       " ('dealer', 1),\n",
       " ('possible', 1),\n",
       " ('gave', 1),\n",
       " ('third', 1),\n",
       " ('rider', 1),\n",
       " ('requested', 1),\n",
       " ('owner', 1),\n",
       " ('first', 1),\n",
       " ('time', 1),\n",
       " ('learned', 1),\n",
       " ('contacted', 1),\n",
       " ('ensured', 1),\n",
       " ('appropriate', 1),\n",
       " ('proper', 1),\n",
       " ('treatment', 1),\n",
       " ('possession', 1),\n",
       " ('substantial', 1),\n",
       " ('cruelty', 1),\n",
       " ('sight', 1),\n",
       " ('together', 1),\n",
       " ('times', 1),\n",
       " ('daniel', 1),\n",
       " ('behavioural', 1),\n",
       " ('specialist', 1),\n",
       " ('university', 1),\n",
       " ('lincoln', 1),\n",
       " ('seen', 1),\n",
       " ('gunshot', 1),\n",
       " ('startling', 1),\n",
       " ('seeing', 1),\n",
       " ('suddenly', 1),\n",
       " ('drop', 1),\n",
       " ('distressing', 1),\n",
       " ('situation', 1),\n",
       " ('breach', 1),\n",
       " ('every', 1),\n",
       " ('effort', 1),\n",
       " ('made', 1),\n",
       " ('ensure', 1),\n",
       " ('rapid', 1),\n",
       " ('sometimes', 1),\n",
       " ('far', 1),\n",
       " ('instant', 1),\n",
       " ('slaughterman', 1),\n",
       " ('shooting', 1),\n",
       " ('close', 1),\n",
       " ('reviewing', 1),\n",
       " ('killing', 1),\n",
       " ('look', 1),\n",
       " ('like', 1),\n",
       " ('even', 1),\n",
       " ('stunned', 1),\n",
       " ('see', 1),\n",
       " ('turning', 1),\n",
       " ('seems', 1),\n",
       " ('control', 1),\n",
       " ('actually', 1),\n",
       " ('neck', 1),\n",
       " ('taking', 1),\n",
       " ('completely', 1),\n",
       " ('order', 1),\n",
       " ('euthanise', 1),\n",
       " ('get', 1),\n",
       " ('bullet', 1),\n",
       " ('right', 1),\n",
       " ('place', 1),\n",
       " ('representative', 1),\n",
       " ('really', 1),\n",
       " ('serious', 1),\n",
       " ('problem', 1),\n",
       " ('maintain', 1),\n",
       " ('conditions', 1),\n",
       " ('destroyed', 1),\n",
       " ('occur', 1),\n",
       " ('swift', 1),\n",
       " ('action', 1),\n",
       " ('review', 1),\n",
       " ('rectify', 1),\n",
       " ('transported', 1),\n",
       " ('road', 1),\n",
       " ('sea', 1),\n",
       " ('injuries', 1),\n",
       " ('hannah', 1),\n",
       " ('reviewed', 1),\n",
       " ('potentially', 1),\n",
       " ('humane', 1),\n",
       " ('process', 1),\n",
       " ('suffering', 1),\n",
       " ('bottom', 1),\n",
       " ('could', 1),\n",
       " ('home', 1),\n",
       " ('simple', 1),\n",
       " ('authorities', 1),\n",
       " ('guidelines', 1),\n",
       " ('clearly', 1),\n",
       " ('happen', 1),\n",
       " ('career', 1),\n",
       " ('ends', 1),\n",
       " ('recommend', 1),\n",
       " ('make', 1),\n",
       " ('provision', 1),\n",
       " ('responsible', 1),\n",
       " ('governing', 1),\n",
       " ('body', 1),\n",
       " ('placed', 1),\n",
       " ('importance', 1),\n",
       " ('british', 1),\n",
       " ('horseracing', 1),\n",
       " ('authority', 1),\n",
       " ('demonstrated', 1),\n",
       " ('commitment', 1),\n",
       " ('improving', 1),\n",
       " ('already', 1),\n",
       " ('standards', 1),\n",
       " ('consider', 1),\n",
       " ('carefully', 1),\n",
       " ('raised', 1),\n",
       " ('programme', 1),\n",
       " ('understand', 1),\n",
       " ('poor', 1),\n",
       " ('record', 1),\n",
       " ('dying', 1),\n",
       " ('longer', 1),\n",
       " ('support', 1),\n",
       " ('think', 1),\n",
       " ('lot', 1),\n",
       " ('public', 1),\n",
       " ('feel', 1),\n",
       " ('way', 1),\n",
       " ('dark', 1),\n",
       " ('side', 1),\n",
       " ('monday', 1),\n",
       " ('bst', 1),\n",
       " ('watch', 1),\n",
       " ('later', 1),\n",
       " ('iplayer', 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_freq2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert the list into an nltk text type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltktext=Text(clean_tokens_lower_without_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltktext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal aid; accept form; dene stansall; designed protect; drury sons;\n",
      "four days; travelling miles; rules designed; former racehorses; gordon\n",
      "elliott; prof mills; animal abuse; britain ireland; form animal;\n",
      "racehorses slaughtered; told panorama; footage recorded; aid cameras;\n",
      "horses industry; horses shot\n"
     ]
    }
   ],
   "source": [
    "#collocations - words that appear next to eachother frequently\n",
    "nltktext.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "february picture top trainer gordon elliott sitting dead horse sent shockwaves \n",
      "sent shockwaves world racing beyond elliott trained three winners grand nationa\n",
      "ousands pounds three trained gordon elliott stables county meath ireland told p\n",
      " racing due injury said care killed elliott said two horses sent horse dealer r\n",
      "ime learned fate panorama contacted elliott said ensured appropriate proper tre\n"
     ]
    }
   ],
   "source": [
    "# concordance - fragments containing key words - indexed - text around that word\n",
    "nltktext.concordance(\"elliott\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltktext.dispersion_plot(['horse', 'racing', 'racehorses','elliott', 'trainer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothingdf=pd.read_csv('Womens Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               23486 non-null  int64 \n",
      " 1   Clothing ID              23486 non-null  int64 \n",
      " 2   Age                      23486 non-null  int64 \n",
      " 3   Title                    19676 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   23486 non-null  int64 \n",
      " 6   Recommended IND          23486 non-null  int64 \n",
      " 7   Positive Feedback Count  23486 non-null  int64 \n",
      " 8   Division Name            23472 non-null  object\n",
      " 9   Department Name          23472 non-null  object\n",
      " 10  Class Name               23472 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "clothingdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Absolutely wonderful - silky and sexy and comfortable\n",
       "1                                                                                                                                                                                                             Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n",
       "2        I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n",
       "4                                                                                                                                                                                                                                                                                                                            This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n",
       "                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                         \n",
       "23481                                                                                                                                                                                                                                                                                                                                                                                     I was very happy to snag this dress at such a great price! it's very easy to slip on and has a very flattering cut and color combo.\n",
       "23482                                                                                                                                                                                                                                                                                        It reminds me of maternity clothes. soft, stretchy, shiny material. cut is flattering and drapes nicely. i only found one button to close front... looked awkward. nice long sleeves.\\nnot for me but maybe for others. just ok.\n",
       "23483                                                                                                                                                                                                                                                                                                        This fit well, but the top was very see through. this never would have worked for me. i'm glad i was able to try it on in the store and didn't order it online. with different fabric, it would have been great.\n",
       "23484                                                                             I bought this dress for a wedding i have this summer, and it's so cute. unfortunately the fit isn't perfect. the medium fits my waist perfectly, but was way too long and too big in the bust and shoulders. if i wanted to spend the money, i could get it tailored, but i just felt like it might not be worth it. side note - this dress was delivered to me with a nordstrom tag on it and i found it much cheaper there after looking!\n",
       "23485                                                                                                                                                                                                                                                                                                                                                                                                          This dress in a lovely platinum is feminine and fits perfectly, easy to wear and comfy, too! highly recommend!\n",
       "Name: Review Text, Length: 23486, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothingdf['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) #setting so we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 2, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothingdf['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=0.3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('best day on my life').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean our data for department, review analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Intimate', 'Dresses', 'Bottoms', 'Tops', 'Jackets', 'Trend', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove nulls from departments, review text\n",
    "clothingdf['Department Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothingdf.dropna(subset=['Review Text', 'Department Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22628 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               22628 non-null  int64 \n",
      " 1   Clothing ID              22628 non-null  int64 \n",
      " 2   Age                      22628 non-null  int64 \n",
      " 3   Title                    19662 non-null  object\n",
      " 4   Review Text              22628 non-null  object\n",
      " 5   Rating                   22628 non-null  int64 \n",
      " 6   Recommended IND          22628 non-null  int64 \n",
      " 7   Positive Feedback Count  22628 non-null  int64 \n",
      " 8   Division Name            22628 non-null  object\n",
      " 9   Department Name          22628 non-null  object\n",
      " 10  Class Name               22628 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "clothingdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                   absolutely wonderful silky sexy comfortable\n",
       "1                                                                                                                             love dress sooo pretty happened find store glad bc never would ordered online bc petite bought petite love length hit little knee would definitely true midi someone truly petite\n",
       "2    high hope dress really wanted work initially ordered petite small usual size found outrageously small small fact could zip reordered petite medium overall top half comfortable fit nicely bottom half tight layer several somewhat cheap net layer imo major design flaw net layer sewn directly zipper c\n",
       "3                                                                                                                                                                                                                      love love love jumpsuit fun flirty fabulous every time wear get nothing great compliment\n",
       "4                                                                                                                                                                                                shirt flattering due adjustable front tie perfect length wear legging sleeveless pair well cardigan love shirt\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothingdf['Review Text']=clothingdf[\"Review Text\"].apply(cleaning)\n",
    "clothingdf['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    #1. Tokenize\n",
    "    text_tokens = word_tokenize(data.replace(\"’\", \"\").lower())\n",
    "    #2. Remove Puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    #3. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    #4. lemma\n",
    "    text_cleaned = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothingdf['sentiment_score']=clothingdf['Review Text'].apply(lambda x:TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothingdf['subjectivity_score']=clothingdf['Review Text'].apply(lambda x:TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age Title  \\\n",
       "0           0          767   33   NaN   \n",
       "\n",
       "                                   Review Text  Rating  Recommended IND  \\\n",
       "0  absolutely wonderful silky sexy comfortable       4                1   \n",
       "\n",
       "   Positive Feedback Count Division Name Department Name Class Name  \\\n",
       "0                        0     Initmates        Intimate  Intimates   \n",
       "\n",
       "   sentiment_score  subjectivity_score  \n",
       "0         0.633333            0.933333  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothingdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11737.272097</td>\n",
       "      <td>919.695908</td>\n",
       "      <td>43.282880</td>\n",
       "      <td>4.183092</td>\n",
       "      <td>0.818764</td>\n",
       "      <td>2.631784</td>\n",
       "      <td>0.256453</td>\n",
       "      <td>0.561387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6781.574232</td>\n",
       "      <td>201.683804</td>\n",
       "      <td>12.328176</td>\n",
       "      <td>1.115911</td>\n",
       "      <td>0.385222</td>\n",
       "      <td>5.787520</td>\n",
       "      <td>0.172490</td>\n",
       "      <td>0.129506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5868.750000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148135</td>\n",
       "      <td>0.480798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11727.500000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.556923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17617.250000</td>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.636799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23485.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   Clothing ID           Age        Rating  \\\n",
       "count  22628.000000  22628.000000  22628.000000  22628.000000   \n",
       "mean   11737.272097    919.695908     43.282880      4.183092   \n",
       "std     6781.574232    201.683804     12.328176      1.115911   \n",
       "min        0.000000      1.000000     18.000000      1.000000   \n",
       "25%     5868.750000    861.000000     34.000000      4.000000   \n",
       "50%    11727.500000    936.000000     41.000000      5.000000   \n",
       "75%    17617.250000   1078.000000     52.000000      5.000000   \n",
       "max    23485.000000   1205.000000     99.000000      5.000000   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count  sentiment_score  \\\n",
       "count     22628.000000             22628.000000     22628.000000   \n",
       "mean          0.818764                 2.631784         0.256453   \n",
       "std           0.385222                 5.787520         0.172490   \n",
       "min           0.000000                 0.000000        -0.800000   \n",
       "25%           1.000000                 0.000000         0.148135   \n",
       "50%           1.000000                 1.000000         0.250000   \n",
       "75%           1.000000                 3.000000         0.360000   \n",
       "max           1.000000               122.000000         1.000000   \n",
       "\n",
       "       subjectivity_score  \n",
       "count        22628.000000  \n",
       "mean             0.561387  \n",
       "std              0.129506  \n",
       "min              0.000000  \n",
       "25%              0.480798  \n",
       "50%              0.556923  \n",
       "75%              0.636799  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothingdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_group_by=clothingdf.groupby(['Department Name']).agg({'sentiment_score':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bottoms</th>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dresses</th>\n",
       "      <td>0.258545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intimate</th>\n",
       "      <td>0.254855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jackets</th>\n",
       "      <td>0.242832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tops</th>\n",
       "      <td>0.257319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trend</th>\n",
       "      <td>0.213744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentiment_score\n",
       "Department Name                 \n",
       "Bottoms                 0.256389\n",
       "Dresses                 0.258545\n",
       "Intimate                0.254855\n",
       "Jackets                 0.242832\n",
       "Tops                    0.257319\n",
       "Trend                   0.213744"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_group_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/js/3prtlh997knckqf8p2nq_dz80000gn/T/ipykernel_7955/572880994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
